from dotenv import load_dotenv
import os
import pandas as pd
import json
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import faiss
import numpy as np
from datetime import datetime
from fastapi import FastAPI, HTTPException, Request
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import RedisChatMessageHistory


# âœ… FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5050"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# âœ… ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ì¶”ê°€ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ë° í•µì‹¬ ë‹¨ì–´ ì €ì¥)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
memoryWord = []  # í•µì‹¬ ë‹¨ì–´ ì €ì¥

# âœ… Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')

# âœ… FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
faiss_file_path = f"faiss_index_{datetime.now().strftime('%Y%m%d')}.faiss"

# âœ… POST ìš”ì²­ì„ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜
class QueryRequest(BaseModel):
    query: str

# âœ… JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ int ë³€í™˜ í•¨ìˆ˜
def convert_to_serializable(obj):
    if isinstance(obj, (np.int64, np.int32, np.float32, np.float64)):
        return obj.item()
    return obj

# âœ… ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜ (ê³µë°± ì œê±°)
def load_excel_to_texts(file_path):
    try:
        data = pd.read_excel(file_path)
        data.columns = data.columns.str.strip()
        texts = [" | ".join([f"{col}: {row[col]}" for col in data.columns]) for _, row in data.iterrows()]
        return texts, data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

# âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
def save_faiss_index(index, file_path):
    try:
        faiss.write_index(index, file_path)
    except Exception as e:
        print(f"âŒ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ
def load_faiss_index(file_path):
    try:
        return faiss.read_index(file_path)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"FAISS ì¸ë±ìŠ¤ ë¡œë”© ì˜¤ë¥˜: {str(e)}")

# âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ (IndexIVFFlat ì ìš©)
def create_and_save_faiss_index(file_path):
    try:
        texts, _ = load_excel_to_texts(file_path)
        ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
        embeddings = ì„ë² ë”©.embed_documents(texts)
        embeddings = np.array(embeddings, dtype=np.float32)
        faiss.normalize_L2(embeddings)

        # âœ… IndexIVFFlat ì‚¬ìš©
        d = embeddings.shape[1]
        nlist = 200  # í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
        quantizer = faiss.IndexFlatL2(d)
        index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)
        index.train(embeddings)
        index.add(embeddings)

        save_faiss_index(index, faiss_file_path)
    except Exception as e:
        print(f"âŒ FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ ì˜¤ë¥˜: {e}")

# âœ… LLMì„ ì´ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ëŒ€í™” ì´ë ¥ ë°˜ì˜
def extract_keywords_with_llm(query):
    llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=API_KEY)

    # âœ… ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
    chat_history = ""

    try:
        # âœ… ë©”ëª¨ë¦¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í™•ì¸
        memory_data = memory.load_memory_variables({})
        if "chat_history" in memory_data and memory_data["chat_history"]:
            chat_history = str(memory_data["chat_history"])
    except Exception as e:
        print(f"ë©”ëª¨ë¦¬ ë¡œë”© ì˜¤ë¥˜: {e}")

    # ê¸°ì¡´ ëŒ€í™” ì´ë ¥ê³¼ í•¨ê»˜ LLMì— ì „ë‹¬
    response = llm.invoke([
        SystemMessage(content="ì‚¬ìš©ìì˜ ëŒ€í™” ë‚´ì—­ì„ ë°˜ì˜í•˜ì—¬ ìƒí’ˆ ê²€ìƒ‰ì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”."),
        HumanMessage(content=f"ì§ˆë¬¸: {query} \n ëŒ€í™” ì´ë ¥: {chat_history}")
    ])
    # í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
    keywords = [keyword.strip() for keyword in response.content.split(",")]
    memoryWord.clear()
    memoryWord.extend(keywords)
    memory.save_context({"input": query}, {"output": keywords})
    combined_keywords = ", ".join(keywords)
    return combined_keywords

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” ìƒì„±
if not os.path.exists(faiss_file_path):
    create_and_save_faiss_index("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")
index = load_faiss_index(faiss_file_path)

# âœ… ë£¨íŠ¸ ê²½ë¡œ - HTML í˜ì´ì§€ ë Œë”ë§
@app.get("/", response_class=HTMLResponse)
async def serve_home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# âœ… ì •í™•ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_accuracies(distances):
    """
    ê±°ë¦¬ ê°’ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    :param distances: FAISSì—ì„œ ë°˜í™˜ëœ ê±°ë¦¬ ê°’ ë¦¬ìŠ¤íŠ¸
    :return: ì •í™•ë„ ë¦¬ìŠ¤íŠ¸ (0.00 ~ 1.00 ë²”ìœ„)
    """
    return [round((1 - dist), 2) for dist in distances]

# âœ… POST ìš”ì²­ ì²˜ë¦¬ - `/chatbot`
@app.post("/chatbot")
def search_and_generate_response(request: QueryRequest):
    query = request.query
    print(f"ğŸ” ì‚¬ìš©ì ê²€ìƒ‰ì–´: {query}")

    try:
        # âœ… LLMì„ í†µí•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì„ë² ë”© ìƒì„±
        combined_keywords = extract_keywords_with_llm(query)
        print(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: {combined_keywords}")
    
        _, data = load_excel_to_texts("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")

        # âœ… OpenAI ì„ë² ë”© ìƒì„±
        ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
        query_embedding = ì„ë² ë”©.embed_query(combined_keywords)
        query_embedding = np.array([query_embedding], dtype=np.float32)
        faiss.normalize_L2(query_embedding)

        # âœ… FAISS ê²€ìƒ‰ ìˆ˜í–‰
        D, I = index.search(query_embedding, k=5)

        # âœ… FAISS ê²€ìƒ‰ ê²°ê³¼ ê²€ì‚¬
        if I is None or len(I) == 0 or not hasattr(I, "__iter__"):
            return {
                "query": query,
                "results": [],
                "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”!"
            }

        # âœ… ê±°ë¦¬ ì„ê³„ê°’ í•„í„°ë§
        threshold = 0.5
        filtered_results = [(dist, int(idx)) for dist, idx in zip(D[0], I[0]) if dist <= threshold]

        # âœ… í•„í„°ë§ í›„ ê²°ê³¼ ì—†ìŒ ë°©ì§€
        if not filtered_results:
            print("âš ï¸ ì„ê³„ê°’ ê¸°ì¤€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return {
                "query": query,
                "results": [],
                "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê¸°ì¤€ì„ ì™„í™”í•˜ê±°ë‚˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            }

        # âœ… ê²°ê³¼ ì–¸íŒ¨í‚¹ ë°©ì§€
        try:
            D, I = zip(*filtered_results)
        except ValueError:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return {
                "query": query,
                "results": [],
                "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”!"
            }
        
        # âœ… ê±°ë¦¬ ê°’ ê¸°ë°˜ìœ¼ë¡œ ì •í™•ë„ ê³„ì‚°
        accuracies = calculate_accuracies(D)

        # âœ… ê²€ìƒ‰ ê²°ê³¼ JSON ë³€í™˜
        results = []
        for idx, accuracy in zip(I, accuracies):
            if idx >= len(data):
                continue
            result_row = data.iloc[idx]
            result_info = {
                "ìƒí’ˆì½”ë“œ": str(result_row["ìƒí’ˆì½”ë“œ"]),
                "ì›ë³¸ìƒí’ˆëª…": result_row["ì›ë³¸ìƒí’ˆëª…"],
                "ì˜¤ë„ˆí´ëœíŒë§¤ê°€": convert_to_serializable(result_row["ì˜¤ë„ˆí´ëœíŒë§¤ê°€"]),
                "ë°°ì†¡ë¹„": convert_to_serializable(result_row["ë°°ì†¡ë¹„"]),
                "ì´ë¯¸ì§€ì¤‘": result_row["ì´ë¯¸ì§€ì¤‘"],
                "ì›ì‚°ì§€": result_row["ì›ì‚°ì§€"],
                "ì •í™•ë„": accuracy  # âœ… ì •í™•ë„ ì¶”ê°€
            }
            results.append(result_info)

        # âœ… ê²€ìƒ‰ ê²°ê³¼ë¥¼ LangChain ë©”ëª¨ë¦¬ì— ì €ì¥ (ëª¨ë“  ì†ì„± ì €ì¥)
        memory.save_context(
            {"input": query},  # ì‚¬ìš©ì ì§ˆë¬¸
            {"output": results}  # ê²€ìƒ‰ ê²°ê³¼ ì „ì²´ ì €ì¥
        )

        # âœ… LLMì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ì§€
        llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18", api_key=API_KEY)
        response = llm.invoke([
            SystemMessage(content=f"ì˜¤ë„ˆí´ëœíŒë§¤ê°€:ê°€ê²©,ì›ë³¸ìƒí’ˆëª…:ìƒí’ˆì˜ ì œëª©. ë‹¹ì‹ ì€ ì‡¼í•‘ëª°ì— ëŒ€í•œ ì§€ì‹ì´ ë†’ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì•„ì£¼ ì¹œì ˆí•˜ê³  ì „ë¬¸ê°€ì¸ ì±—ë´‡ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ ê°„ê²°í•˜ê³  ì‰½ê²Œ ë‹µë³€í•©ë‹ˆë‹¤."),
            HumanMessage(content=f"ì‚¬ìš©ì ìš”ì²­: {query} \n ê²€ìƒ‰ëœ ê²°ê³¼:\n{json.dumps(results, ensure_ascii=False, indent=2)}\n ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."),
        ])

        # âœ… JSON ë°˜í™˜
        return {
            "query": query,
            "results": results,
            "llm_response": response.content,
            "chat_history": memory.load_memory_variables({}),
            "extracted_keywords": memoryWord,
            "ì •í™•ë„" : accuracy
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# âœ… FastAPI ì„œë²„ ì‹¤í–‰ (í¬íŠ¸ ê³ ì •: 5050)
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5050)
