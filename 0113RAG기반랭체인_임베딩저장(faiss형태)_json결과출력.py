from dotenv import load_dotenv
import os
import pandas as pd
import json
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import faiss
import numpy as np
from datetime import datetime

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')

# âœ… ì˜¤ëŠ˜ ë‚ ì§œë¡œ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ ìƒì„±
faiss_file_path = f"faiss_index_{datetime.now().strftime('%Y%m%d')}.faiss"

# âœ… ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜ (ê³µë°± ì œê±°)
def load_excel_to_texts(file_path):
    try:
        data = pd.read_excel(file_path)
        data.columns = data.columns.str.strip()  # ê³µë°± ì œê±°
        texts = [
            " | ".join([f"{col}: {row[col]}" for col in data.columns])
            for _, row in data.iterrows()
        ]
        return texts, data
    except Exception as e:
        print(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise

# âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ (CPU ë²„ì „)
def save_faiss_index(index, file_path):
    faiss.write_index(index, file_path)
    print(f"âœ… FAISS ì¸ë±ìŠ¤ê°€ {file_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ
def load_faiss_index(file_path):
    try:
        index = faiss.read_index(file_path)
        print(f"âœ… FAISS ì¸ë±ìŠ¤ê°€ {file_path}ì—ì„œ ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return index
    except Exception as e:
        print(f"âŒ FAISS ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# âœ… OpenAI ì„ë² ë”© ë° FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
def create_and_save_faiss_index(file_path):
    texts, _ = load_excel_to_texts(file_path)
    ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
    
    # âœ… ì„ë² ë”© ë²¡í„° ìƒì„±
    embeddings = ì„ë² ë”©.embed_documents(texts)
    
    # âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± (CPU ë²„ì „)
    index = faiss.IndexFlatL2(1536)
    index.add(np.array(embeddings, dtype=np.float32))
    
    # âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
    save_faiss_index(index, faiss_file_path)

# âœ… ë©”ì¸ ì‹¤í–‰ ë¡œì§: ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸ í›„ ë¡œë”© ë˜ëŠ” ìƒˆë¡œ ìƒì„±
if os.path.exists(faiss_file_path):
    print(f"ğŸ“¦ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ë°œê²¬: {faiss_file_path}")
    index = load_faiss_index(faiss_file_path)
else:
    print("âš™ï¸ FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    create_and_save_faiss_index("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")
    index = load_faiss_index(faiss_file_path)

# âœ… ë²¡í„° ìˆ˜ ë° ì°¨ì› ìˆ˜ ì¶œë ¥
if index:
    print(f"âœ… ì €ì¥ëœ ë²¡í„° ìˆ˜: {index.ntotal}")
    print(f"âœ… ë²¡í„° ì°¨ì› ìˆ˜: {index.d}")
else:
    print("âŒ FAISS ì¸ë±ìŠ¤ ë¡œë”©ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")

#########============ì„ë² ë”© ì €ì¥ í›„ ë¡œë“œ ë° JSON ë³€í™˜============#########

# âœ… JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ int ë³€í™˜ í•¨ìˆ˜
def convert_to_serializable(obj):
    if isinstance(obj, np.int64):
        return int(obj)
    return obj

# âœ… ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰ ë° JSON ê²°ê³¼ ë°˜í™˜
def search_and_generate_response(file_path):
    query = input("ğŸ’¬ ìƒí’ˆ ê²€ìƒ‰ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    index = load_faiss_index(file_path)
    _, data = load_excel_to_texts("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")

    if index is None:
        print("âŒ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return json.dumps({"error": "FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)

    # âœ… OpenAI ì„ë² ë”© ìƒì„±
    ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
    query_embedding = ì„ë² ë”©.embed_query(query)

    # âœ… FAISS ê²€ìƒ‰ ìˆ˜í–‰
    D, I = index.search(np.array([query_embedding], dtype=np.float32), k=5)

    # âœ… ê²€ìƒ‰ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (int64 â†’ int ë³€í™˜ ì ìš©)
    results = []
    for idx in I[0]:
        if idx >= len(data):
            continue
        result_row = data.iloc[idx]
        result_info = {
            "ìƒí’ˆì½”ë“œ": str(result_row["ìƒí’ˆì½”ë“œ"]),  # ë¬¸ìì—´ ë³€í™˜ ì ìš©
            "ì›ë³¸ìƒí’ˆëª…": result_row["ì›ë³¸ìƒí’ˆëª…"],
            "ì˜¤ë„ˆí´ëœíŒë§¤ê°€": convert_to_serializable(result_row["ì˜¤ë„ˆí´ëœíŒë§¤ê°€"]),
            "ë°°ì†¡ë¹„": convert_to_serializable(result_row["ë°°ì†¡ë¹„"]),
            "ì´ë¯¸ì§€ì¤‘": result_row["ì´ë¯¸ì§€ì¤‘"],
            "ì›ì‚°ì§€": result_row["ì›ì‚°ì§€"]
        }
        results.append(result_info)

    # âœ… LLMì„ ì‚¬ìš©í•˜ì—¬ JSON ê¸°ë°˜ ì„¤ëª… ìƒì„±
    llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18", api_key=API_KEY)
    response = llm.invoke(f"ì‚¬ìš©ìê°€ ìš”ì²­í•œ '{query}'ì— ëŒ€í•œ ìƒìœ„ 5ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {json.dumps(results, ensure_ascii=False)}")

    # âœ… ìµœì¢… JSON ì§ë ¬í™”ë¡œ ê²°ê³¼ ë°˜í™˜ (int64 ë³€í™˜ í¬í•¨)
    final_output = {
        "query": query,
        "results": results,
        "llm_response": str(response)
    }

    # âœ… JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥
    print(json.dumps(final_output, ensure_ascii=False, indent=4, default=convert_to_serializable))

# âœ… ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ë° JSON ì‘ë‹µ ìƒì„±
search_and_generate_response(faiss_file_path)
