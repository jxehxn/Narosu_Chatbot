from dotenv import load_dotenv
import os
import pandas as pd
import json
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import faiss
import numpy as np
from datetime import datetime
from fastapi import FastAPI, HTTPException, Request
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain_core.runnables import ConfigurableFieldSpec
import redis
import requests
from typing import Union
import logging
import time
from celery import Celery



# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')
REDIS_URL = "redis://localhost:6379/0"
VERIFY_TOKEN = os.getenv('VERIFY_TOKEN')
PAGE_ACCESS_TOKEN = os.getenv('PAGE_ACCESS_TOKEN')
MANYCHAT_API_KEY = os.getenv('MANYCHAT_API_KEY')

print(f"ğŸ” ë¡œë“œëœ VERIFY_TOKEN: {VERIFY_TOKEN}")
print(f"ğŸ” ë¡œë“œëœ PAGE_ACCESS_TOKEN: {PAGE_ACCESS_TOKEN}")

celery_app = Celery(
    'tasks',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/0'
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("response_time_logger")

# âœ… FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
faiss_file_path = f"faiss_index_02M.faiss"

def get_redis():
    return redis.Redis.from_url(REDIS_URL)

# âœ… FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5050", "https://satyr-inviting-quetzal.ngrok-free.app"],  # ì™¸ë¶€ ë„ë©”ì¸ ì¶”ê°€
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("response_time_logger")

celery_app.conf.update(
    imports=["0124_01mnaychatìµœì í™”"]  # ì‘ì—… ëª¨ë“ˆ ê²½ë¡œ
)
@celery_app.task
def process_message_task(sender_id, user_message):
    """
    Celery ë¹„ë™ê¸° ì‘ì—…ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„± ë° ì „ì†¡í•©ë‹ˆë‹¤.
    """
    try:
        # Step 3: ì‘ë‹µ ìƒì„±
        print("Celery ë¹„ë™ê¸° ìƒì„±ì‹œì‘ì‘")
        search_start = time.time()
        bot_response = search_and_generate_response2(user_message, session_id=sender_id)
        search_time = time.time() - search_start
        logger.info(f"ğŸ“Š [Step 3] search_and_generate_response2 í˜¸ì¶œ ì‹œê°„: {search_time:.4f} ì´ˆ")

        # ì‘ë‹µ í™•ì¸
        if isinstance(bot_response, dict) and "response" in bot_response:
            response_text = bot_response["response"]
        else:
            response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ì‚¬ìš©ìì—ê²Œ ì‘ë‹µ ì „ì†¡
        send_message(sender_id, response_text)
        logger.info(f"ğŸ¤– [Sent to User] {response_text}")

    except Exception as e:
        print("Celery ë¹„ë™ê¸° ìƒì„± ì•ˆ í•œë“¯.")
        logger.error(f"âŒ ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")





# ì‘ë‹µ ì†ë„ ì¸¡ì •ì„ ìœ„í•œ ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
@app.middleware("http")
async def measure_response_time(request: Request, call_next):
    start_time = time.time()  # ìš”ì²­ ì‹œì‘ ì‹œê°„
    response = await call_next(request)  # ìš”ì²­ ì²˜ë¦¬
    process_time = time.time() - start_time  # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    response.headers["ngrok-skip-browser-warning"] = "true"
    
    # '/chatbot' ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ ì‘ë‹µ ì†ë„ ë¡œê¹…
    if request.url.path == "/webhook":
        print(f"ğŸ“Š [TEST] Endpoint: {request.url.path}, ì²˜ë¦¬ ì‹œê°„: {process_time:.4f} ì´ˆ")  # printë¡œ ì§ì ‘ í™•ì¸
        logger.info(f"ğŸ“Š [Endpoint: {request.url.path}] ì²˜ë¦¬ ì‹œê°„: {process_time:.4f} ì´ˆ")
    
    response.headers["X-Process-Time"] = str(process_time)  # ì‘ë‹µ í—¤ë”ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
    return response

# âœ… Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")

# âœ… Redis ê¸°ë°˜ ë©”ì‹œì§€ ê¸°ë¡ ê´€ë¦¬ í•¨ìˆ˜
def get_message_history(session_id: str) -> RedisChatMessageHistory:
    """
    Redisë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    :param session_id: ì‚¬ìš©ìì˜ ê³ ìœ  ì„¸ì…˜ ID
    :return: RedisChatMessageHistory ê°ì²´
    """
    try:
        history = RedisChatMessageHistory(session_id=session_id, url=REDIS_URL)
        return history
    except Exception as e:
        print(f"âŒ Redis ì—°ê²° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="Redis ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ìš”ì²­ ëª¨ë¸
class QueryRequest(BaseModel):
    query: str


# âœ… JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ int ë³€í™˜ í•¨ìˆ˜
def convert_to_serializable(obj):
    if isinstance(obj, (np.int64, np.int32, np.float32, np.float64)):
        return obj.item()
    return obj

# âœ… ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜ (ê³µë°± ì œê±°)
def load_excel_to_texts(file_path):
    try:
        data = pd.read_excel(file_path)
        data.columns = data.columns.str.strip()
        texts = [" | ".join([f"{col}: {row[col]}" for col in data.columns]) for _, row in data.iterrows()]
        return texts, data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

# âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
def save_faiss_index(index, file_path):
    try:
        faiss.write_index(index, file_path)
    except Exception as e:
        print(f"âŒ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ
def load_faiss_index(file_path):
    try:
        return faiss.read_index(file_path)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"FAISS ì¸ë±ìŠ¤ ë¡œë”© ì˜¤ë¥˜: {str(e)}")

# âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ (IndexIVFFlat ì ìš©)
def create_and_save_faiss_index(file_path):
    try:
        texts, _ = load_excel_to_texts(file_path)
        ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
        embeddings = ì„ë² ë”©.embed_documents(texts)
        embeddings = np.array(embeddings, dtype=np.float32)
        faiss.normalize_L2(embeddings)

        # âœ… IndexIVFFlat ì‚¬ìš©
        d = embeddings.shape[1]
        nlist = 200  # í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
        quantizer = faiss.IndexFlatL2(d)
        index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)
        index.train(embeddings)
        index.add(embeddings)

        save_faiss_index(index, faiss_file_path)
    except Exception as e:
        print(f"âŒ FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ ì˜¤ë¥˜: {e}")

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” ìƒì„±
if not os.path.exists(faiss_file_path):
    create_and_save_faiss_index("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")
index = load_faiss_index(faiss_file_path)

# âœ… LLMì„ ì´ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ëŒ€í™” ì´ë ¥ ë°˜ì˜
def extract_keywords_with_llm(query):
    redis_start = time.time()

    llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=API_KEY)

    # ê¸°ì¡´ ëŒ€í™” ì´ë ¥ê³¼ í•¨ê»˜ LLMì— ì „ë‹¬
    response = llm.invoke([
        SystemMessage(content="ì‚¬ìš©ìì˜ ëŒ€í™” ë‚´ì—­ì„ ë°˜ì˜í•˜ì—¬ ìƒí’ˆ ê²€ìƒ‰ì„ ìœ„í•œ ì •ë§ë¡œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë§Œì•½ ë‹¨ì–´ ê°„ì— ë„ì–´ì“°ê¸°ê°€ ìˆë‹¤ë©´ í•˜ë‚˜ì˜ ë‹¨ì–´ ì¼ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ ë„ì–´ì“°ê¸°ê°€ ìˆë‹¤ë©´ ë‹¨ì–´ë¼ë¦¬ ë¶™ì—¬ì„œë„ ë¬¸ì¥ì„ ë¶„ì„í•´ë³´ì„¸ìš”ìš”. ì—¬ëŸ¬ë°©ë²•ìœ¼ë¡œ ìƒê°í•´ì„œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ë‚˜ë¼ ì–¸ì–´ë¡œ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì§ˆë¬¸ì„ ë¨¼ì € í•œê¸€ë¡œ ë²ˆì—­í•´ì„œ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."),
        HumanMessage(content=f"ì§ˆë¬¸: {query} \n ")
    ])

    # í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
    keywords = [keyword.strip() for keyword in response.content.split(",")]
    combined_keywords = ", ".join(keywords)
    redis_time = time.time() - redis_start
    logger.info(f"ğŸ“Š LLMì„ ì´ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œê°„ê°„: {redis_time:.4f} ì´ˆ")

    return combined_keywords

store = {}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    # ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ëŒ€í™” ê¸°ë¡ì´ ì €ì¥ì†Œì— ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ChatMessageHistoryë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    # ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    return store[session_id]

def clear_message_history(session_id: str):
    """
    Redisì— ì €ì¥ëœ íŠ¹ì • ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    try:
        history = RedisChatMessageHistory(session_id=session_id, url=REDIS_URL)
        history.clear()
        print(f"âœ… ì„¸ì…˜ {session_id}ì˜ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ Redis ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")






@app.get("/webhook")
async def verify_webhook(request: Request):
    try:
        
        mode = request.query_params.get("hub.mode")
        token = request.query_params.get("hub.verify_token")
        challenge = request.query_params.get("hub.challenge")
        
        print(f"ğŸ” ë°›ì€ Verify Token: {token}")
        print(f"ğŸ” ì„œë²„ Verify Token: {VERIFY_TOKEN}")
        
        if mode == "subscribe" and token == VERIFY_TOKEN:
            print("âœ… ì›¹í›… ì¸ì¦ ì„±ê³µ")
            return int(challenge)
        else:
            print("âŒ ì›¹í›… ì¸ì¦ ì‹¤íŒ¨")
            return {"status": "error", "message": "Invalid token"}
    except Exception as e:
        print(f"âŒ ì¸ì¦ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"status": "error", "message": str(e)}
    
@app.post("/webhook")
async def handle_webhook(request: Request):
    start_time = time.time()

    try:
        # Step 1: ìš”ì²­ ë°ì´í„° ë¡œë“œ
        data = await request.json()
        parse_time = time.time() - start_time
        logger.info(f"ğŸ“Š [Parse Time]: {parse_time:.4f} ì´ˆ")

        # Step 2: ë©”ì‹œì§€ ì²˜ë¦¬
        process_start = time.time()

        if data.get("field") == "messages":  # field ê°’ì´ 'messages'ì¸ì§€ í™•ì¸
            value = data.get("value", {})  # value í•„ë“œ ê°€ì ¸ì˜¤ê¸°

            # Redis ì„¸ì…˜ ID ì„¤ì •
            sender_id = value.get("sender", {}).get("id")  # ë°œì‹ ì ID
            # print(f"ìœ ì €ì•„ì´ë”” : {sender_id}")

            # ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
            user_message = value.get("message", {}).get("text", "").strip()  # ë©”ì‹œì§€ í…ìŠ¤íŠ¸
            # print(f"ìœ ì €ë©”ì„¸ì§€ : {user_message}")
            print("ë¹„ë™ê¸° ì‘ì—… ì‹œì‘")

            if sender_id and user_message:
                # ë¹„ë™ê¸° ì‘ì—… íì— ì¶”ê°€
                print("ë¹„ë™ê¸° ì‘ì—… ë“¤ì–´ì™”ë”°!")
                process_message_task.delay(sender_id, user_message)  # Celery ì‘ì—… í˜¸ì¶œ
                logger.info(f"ğŸ“Š [Task Queued] User: {sender_id}, Message: {user_message}")

        process_time = time.time() - process_start
        logger.info(f"ğŸ“Š [Processing Time ë©”ì‹œì§€ ì²˜ë¦¬ ì „ì²´ ì‹œê°„]: {process_time:.4f} ì´ˆ")
        print(data)

        print("ë¹„ë™ê¸° ì‘ì—… ëë‚œê±´ê°€?")
        return {
            "version": "v2",
            "content": {
                "messages": [
                    {
                        "type": "text",
                        "text": "ì…ë ¥ì´ ì™„ë£Œ ë˜ì–´ AIê°€ ìƒê°ì¤‘ì…ë‹ˆë‹¤.."
                    }
                ]
            }
        }    
    
    except Exception as e:
        print(f"âŒ ì›¹í›… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))



def search_and_generate_response2(request: Union[QueryRequest, str], session_id: str = None) -> dict:
    query = request

    # Reset ìš”ì²­ ì²˜ë¦¬
    if query.lower() == "reset":
        if session_id:
            clear_message_history(session_id)
        return {"message": f"ì„¸ì…˜ {session_id}ì˜ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."}

    print(f"ğŸ” ì‚¬ìš©ì ê²€ìƒ‰ì–´: {query}")

    try:
        # Step 1: Redis ë©”ì‹œì§€ ê¸°ë¡ ê´€ë¦¬
        redis_start = time.time()
        session_history = get_message_history(session_id)
        redis_time = time.time() - redis_start
        logger.info(f"ğŸ“Š [Step 1] Redis ë©”ì‹œì§€ ê¸°ë¡ ê´€ë¦¬ ì‹œê°„: {redis_time:.4f} ì´ˆ")

        # âœ… ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ í™•ì¸
        print(f"ğŸ” Redis ë©”ì‹œì§€ ê¸°ë¡ (ì´ˆê¸° ìƒíƒœ): {session_history.messages}")

        # âœ… ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ í™•ì¸
        previous_queries = [
            msg.content for msg in session_history.messages if isinstance(msg, HumanMessage)
        ]
        print(f"ğŸ” Redis ë©”ì‹œì§€ ê¸°ë¡: {previous_queries}")


        # Step 2: LLM í‚¤ì›Œë“œ ì¶”ì¶œ
        llm_start = time.time()

        # âœ… LLMì„ í†µí•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì„ë² ë”© ìƒì„±
        combined_query = " ".join(previous_queries + [query])
        combined_keywords = extract_keywords_with_llm(combined_query)
        print(f"âœ… ìƒì„±ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: {combined_keywords}")
        llm_time = time.time() - llm_start
        logger.info(f"ğŸ“Š [Step 2] LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œê°„: {llm_time:.4f} ì´ˆ")

        # âœ… Redisì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        session_history.add_message(HumanMessage(content=query))
        print(f"ï¿½ï¿½ Redis ë©”ì‹œì§€ ê¸°ë¡ (ë³€ê²½ëœ ìƒíƒœ): {session_history.messages}")

        _, data = load_excel_to_texts("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")

        # âœ… OpenAI ì„ë² ë”© ìƒì„±
        embedding_start = time.time()
        ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
        query_embedding = ì„ë² ë”©.embed_query(combined_keywords)
        query_embedding = np.array([query_embedding], dtype=np.float32)
        faiss.normalize_L2(query_embedding)
        embedding_time = time.time() - embedding_start
        logger.info(f"ğŸ“Š [Step 3] OpenAI ì„ë² ë”© ìƒì„± ì‹œê°„: {embedding_time:.4f} ì´ˆ")


        # âœ… FAISS ê²€ìƒ‰ ìˆ˜í–‰
        faiss_start = time.time()
        D, I = index.search(query_embedding, k=5)
        faiss_time = time.time() - faiss_start
        logger.info(f"ğŸ“Š [Step 4] FAISS ê²€ìƒ‰ ì‹œê°„: {faiss_time:.4f} ì´ˆ")

        # âœ… FAISS ê²€ìƒ‰ ê²°ê³¼ ê²€ì‚¬
        results_processing_start = time.time()       
        if I is None or I.size == 0:
            return {
                "query": query,
                "results": [],
                "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”!",
                "message_history": [
                    {"type": type(msg).__name__, "content": msg.content if hasattr(msg, "content") else str(msg)}
                    for msg in session_history.messages
                ],
            }



        # âœ… ê²€ìƒ‰ ê²°ê³¼ JSON ë³€í™˜
        results = []
        for idx_list in I:  # 2ì°¨ì› ë°°ì—´ ì²˜ë¦¬
            for idx in idx_list:
                if idx >= len(data):  # ì˜ëª»ëœ ì¸ë±ìŠ¤ ë°©ì§€
                    continue
                result_row = data.iloc[idx]
                result_info = {
                    "ìƒí’ˆì½”ë“œ": str(result_row["ìƒí’ˆì½”ë“œ"]),
                    "ì œëª©": result_row["ì›ë³¸ìƒí’ˆëª…"],
                    "ê°€ê²©": convert_to_serializable(result_row["ì˜¤ë„ˆí´ëœíŒë§¤ê°€"]),
                    "ë°°ì†¡ë¹„": convert_to_serializable(result_row["ë°°ì†¡ë¹„"]),
                    "ì´ë¯¸ì§€": result_row["ì´ë¯¸ì§€ì¤‘"],
                    "ì›ì‚°ì§€": result_row["ì›ì‚°ì§€"]
                }
                results.append(result_info)

        results_processing_time = time.time() - results_processing_start
        logger.info(f"ğŸ“Š [Step 5] ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì‹œê°„: {results_processing_time:.4f} ì´ˆ")


        # âœ… resultsë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if results:
            results_text = "\n".join(
                [
                    f"ìƒí’ˆì½”ë“œ: {item['ìƒí’ˆì½”ë“œ']}, ì œëª©: {item['ì œëª©']}, ê°€ê²©: {item['ê°€ê²©']}ì›, "
                    f"ë°°ì†¡ë¹„: {item['ë°°ì†¡ë¹„']}ì›, ì›ì‚°ì§€: {item['ì›ì‚°ì§€']}, ì´ë¯¸ì§€: {item['ì´ë¯¸ì§€']}"
                    for item in results
                ]
            )
        else:
            results_text = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                
        message_history=[]

        start_response = time.time()    
        # âœ… ChatPromptTemplate ë° RunnableWithMessageHistory ìƒì„±
        llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=API_KEY)
        prompt = ChatPromptTemplate.from_messages([
            ("system", f"""ë‹¹ì‹ ì€ ì‡¼í•‘ëª° ì±—ë´‡ìœ¼ë¡œ, ì¹œì ˆí•˜ê³  ì¸ê°„ì ì¸ ëŒ€í™”ë¥¼ í†µí•´ ê³ ê°ì˜ ì‡¼í•‘ ê²½í—˜ì„ ë•ìŠµë‹ˆë‹¤.
                            ëª©í‘œ: ì‚¬ìš©ìì˜ ìš”êµ¬ë¥¼ ì´í•´í•˜ê³  ëŒ€í™”ì˜ ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ ì í•©í•œ ìƒí’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.
                            ì‘ë™ ë°©ì‹:ëŒ€í™” ì´ë ¥ì„ ì°¸ê³ í•´ ë¬¸ë§¥ì„ íŒŒì•…í•˜ê³  ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ìƒí’ˆì„ ì—°ê²°í•©ë‹ˆë‹¤.
                            í•„ìš”í•œ ê²½ìš° í›„ì† ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”êµ¬ë¥¼ êµ¬ì²´í™”í•©ë‹ˆë‹¤.
                            ëŒ€í™” ì „ëµ:ìì—°ìŠ¤ëŸ½ê³  ê³µê° ìˆê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©° ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ìƒí’ˆì„ ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
                            ê³ ê°ì´ í¸ì•ˆí•œ ì‡¼í•‘ ê²½í—˜ì„ ëˆ„ë¦´ ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í•©ë‹ˆë‹¤."""),
            MessagesPlaceholder(variable_name="message_history"),
            ("system", f"ë‹¤ìŒì€ ëŒ€í™”ì´ë ¥ì…ë‹ˆë‹¤ : \n{session_history.messages}"),
            ("system", f"ë‹¤ìŒì€ ìƒí’ˆê²°ê³¼ì…ë‹ˆë‹¤ : \n{results_text}"),
            ("human", query)
        ])
        
        runnable = prompt | llm

        with_message_history = RunnableWithMessageHistory(
            runnable,
            get_session_history,
            input_messages_key="input",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤
            history_messages_key="message_history",
        )

        

        # âœ… LLM ì‹¤í–‰ ë° ë©”ì‹œì§€ ê¸°ë¡ ì—…ë°ì´íŠ¸
        response = with_message_history.invoke(
            {"input": query},
            config={"configurable": {"session_id": session_id}}
        )

        response_time = time.time() - start_response
        print(f"ğŸ” ì‘ë‹µ ìƒì„± ì‹œê°„: {response_time:.4f} ì´ˆ")

        # âœ… Redisì— AI ì‘ë‹µ ì¶”ê°€
        session_history.add_message(AIMessage(content=response.content))

        # âœ… ë©”ì‹œì§€ ê¸°ë¡ì„ Redisì—ì„œ ê°€ì ¸ì˜¤ê¸°
        session_history = get_message_history(session_id)
        message_history = [
            {"type": type(msg).__name__, "content": msg.content if hasattr(msg, "content") else str(msg)}
            for msg in session_history.messages
        ]


        # âœ… ì¶œë ¥ ë””ë²„ê¹…
        print("*** Response:", response)
        print("*** Message History:", message_history)

        # âœ… JSON ë°˜í™˜
        return {
            "query": query,
            "results": results,
            "response": response.content,
            "message_history": message_history
        }
    
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ë¡œê¹…
        total_time = time.time() - start_time
        logger.info(f"ğŸ“Š [Total Time] ì „ì²´ search_and_generate_response2 ì²˜ë¦¬ ì‹œê°„: {total_time:.4f} ì´ˆ")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    


def generate_bot_response(user_message: str) -> str:
    """
    ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ ì±—ë´‡ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # âœ… Redisë¥¼ ì´ìš©í•œ ì„¸ì…˜ ê´€ë¦¬
        session_id = f"user_{user_message[:10]}"  # ê°„ë‹¨í•œ ì„¸ì…˜ ID ìƒì„± (í•„ìš” ì‹œ ì‚¬ìš©ì ID ì‚¬ìš©)
        session_history = get_message_history(session_id)

        # âœ… Redisì—ì„œ ê¸°ì¡´ ëŒ€í™” ì´ë ¥ í™•ì¸
        print(f"ğŸ” Redis ë©”ì‹œì§€ ê¸°ë¡ (ì´ˆê¸° ìƒíƒœ): {session_history.messages}")

        # âœ… ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë¡ì— ì¶”ê°€
        session_history.add_message(HumanMessage(content=user_message))

        # âœ… LLM ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=API_KEY)
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ì‚¬ìš©ì ë©”ì‹œì§€ì— ë”°ë¼ ì ì ˆí•˜ê³  ì¹œì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”."),
            MessagesPlaceholder(variable_name="message_history"),
            ("human", user_message)
        ])
        runnable = prompt | llm
        response = runnable.invoke(
            {"input": user_message},
            config={"configurable": {"session_id": session_id}}
        )

        # âœ… Redisì— ì±—ë´‡ ì‘ë‹µ ì €ì¥
        session_history.add_message(AIMessage(content=response.content))

        return response.content
    except Exception as e:
        print(f"âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

def send_message(recipient_id: str, message_text: str):
    # """
    # Facebook Send APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
    # """
    # url = "https://graph.facebook.com/v22.0/me/messages"
    # headers = {"Content-Type": "application/json"}
    # payload = {
    #     "recipient": {"id": recipient_id},
    #     "message": {"text": message_text},
    # }
    # params = {"access_token": PAGE_ACCESS_TOKEN}
    # response = requests.post(url, headers=headers, json=payload, params=params)
    
    # if response.status_code == 200:
    #     print(f"âœ… ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ: {response.json()}")
    # else:
    #     print(f"âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}, {response.text}")

    url = "https://api.manychat.com/fb/sending/sendContent"
    headers = {
        "Authorization": f"Bearer {MANYCHAT_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "subscriber_id": recipient_id,
        "data": {
            "version": "v2",
            "content": {
                "messages": [
                    {"type": "text", "text": message_text}
                ]
            }
        },
        "message_tag": "ACCOUNT_UPDATE"
    }
    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        print(f"âœ… ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ: {response.json()}")
    else:
        print(f"âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}, {response.text}")






# âœ… ë£¨íŠ¸ ê²½ë¡œ - HTML í˜ì´ì§€ ë Œë”ë§
@app.get("/", response_class=HTMLResponse)
async def serve_home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# âœ… POST ìš”ì²­ ì²˜ë¦¬ - `/chatbot`
@app.post("/chatbot")
def search_and_generate_response(request: QueryRequest):
    query = request.query
    session_id = "redis123"  # ê³ ì •ëœ ì„¸ì…˜ ID


    reset_request = request.query.lower() == "reset"  # 'reset' ëª…ë ¹ìœ¼ë¡œ ì´ˆê¸°í™”
    if reset_request:
        clear_message_history(session_id)
        return {
            "message": f"ì„¸ì…˜ {session_id}ì˜ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        }



    print(f"ğŸ” ì‚¬ìš©ì ê²€ìƒ‰ì–´: {query}")

    try:
        # âœ… Redis ë©”ì‹œì§€ ê¸°ë¡ ê´€ë¦¬
        session_history = get_message_history(session_id)
        # âœ… ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ í™•ì¸
        print(f"ğŸ” Redis ë©”ì‹œì§€ ê¸°ë¡ (ì´ˆê¸° ìƒíƒœ): {session_history.messages}")

        # âœ… ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ í™•ì¸
        previous_queries = [
            msg.content for msg in session_history.messages if isinstance(msg, HumanMessage)
        ]
        print(f"ğŸ” Redis ë©”ì‹œì§€ ê¸°ë¡: {previous_queries}")

        # âœ… LLMì„ í†µí•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì„ë² ë”© ìƒì„±
        combined_query = " ".join(previous_queries + [query])
        combined_keywords = extract_keywords_with_llm(combined_query)
        print(f"âœ… ìƒì„±ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: {combined_keywords}")

        # âœ… Redisì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        session_history.add_message(HumanMessage(content=query))
        print(f"ï¿½ï¿½ Redis ë©”ì‹œì§€ ê¸°ë¡ (ë³€ê²½ëœ ìƒíƒœ): {session_history.messages}")

        _, data = load_excel_to_texts("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")

        # âœ… OpenAI ì„ë² ë”© ìƒì„±
        ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
        query_embedding = ì„ë² ë”©.embed_query(combined_keywords)
        query_embedding = np.array([query_embedding], dtype=np.float32)
        faiss.normalize_L2(query_embedding)

        # âœ… FAISS ê²€ìƒ‰ ìˆ˜í–‰
        D, I = index.search(query_embedding, k=5)

        # âœ… FAISS ê²€ìƒ‰ ê²°ê³¼ ê²€ì‚¬
        if I is None or I.size == 0:
            return {
                "query": query,
                "results": [],
                "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”!",
                "message_history": [
                    {"type": type(msg).__name__, "content": msg.content if hasattr(msg, "content") else str(msg)}
                    for msg in session_history.messages
                ],
            }



        # âœ… ê²€ìƒ‰ ê²°ê³¼ JSON ë³€í™˜
        results = []
        for idx_list in I:  # 2ì°¨ì› ë°°ì—´ ì²˜ë¦¬
            for idx in idx_list:
                if idx >= len(data):  # ì˜ëª»ëœ ì¸ë±ìŠ¤ ë°©ì§€
                    continue
                result_row = data.iloc[idx]
                result_info = {
                    "ìƒí’ˆì½”ë“œ": str(result_row["ìƒí’ˆì½”ë“œ"]),
                    "ì œëª©": result_row["ì›ë³¸ìƒí’ˆëª…"],
                    "ê°€ê²©": convert_to_serializable(result_row["ì˜¤ë„ˆí´ëœíŒë§¤ê°€"]),
                    "ë°°ì†¡ë¹„": convert_to_serializable(result_row["ë°°ì†¡ë¹„"]),
                    "ì´ë¯¸ì§€": result_row["ì´ë¯¸ì§€ì¤‘"],
                    "ì›ì‚°ì§€": result_row["ì›ì‚°ì§€"]
                }
                results.append(result_info)

        # âœ… resultsë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if results:
            results_text = "\n".join(
                [
                    f"ìƒí’ˆì½”ë“œ: {item['ìƒí’ˆì½”ë“œ']}, ì œëª©: {item['ì œëª©']}, ê°€ê²©: {item['ê°€ê²©']}ì›, "
                    f"ë°°ì†¡ë¹„: {item['ë°°ì†¡ë¹„']}ì›, ì›ì‚°ì§€: {item['ì›ì‚°ì§€']}, ì´ë¯¸ì§€: {item['ì´ë¯¸ì§€']}"
                    for item in results
                ]
            )
        else:
            results_text = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                
        message_history=[]
        
        # âœ… ChatPromptTemplate ë° RunnableWithMessageHistory ìƒì„±
        llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=API_KEY)
        prompt = ChatPromptTemplate.from_messages([
            ("system", f"""í•­ìƒ message_historyì˜ ëŒ€í™”ì´ë ¥ì„ ë³´ë©´ì„œ ëŒ€í™”ì˜ ë¬¸ë§¥ì„ ì´í•´í•©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì‡¼í•‘ëª° ì±—ë´‡ìœ¼ë¡œ, ì¹œì ˆí•˜ê³  ì¸ê°„ì ì¸ ëŒ€í™”ë¥¼ í†µí•´ ê³ ê°ì˜ ì‡¼í•‘ ê²½í—˜ì„ ë•ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ìµœê·¼ ê²€ìƒ‰ëœ ìƒí’ˆ ëª©ë¡ì…ë‹ˆë‹¤.
            ëª©í‘œ: ì‚¬ìš©ìì˜ ìš”êµ¬ë¥¼ ëª…í™•íˆ ì´í•´í•˜ê³ , ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ê¸°ì–µí•´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.
            ì‘ë™ ë°©ì‹:
            ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì í•©í•œ ìƒí’ˆì„ ì—°ê²°í•©ë‹ˆë‹¤.
            ì´ê±´ ëŒ€í™” ì´ë ¥ ë¬¸ì¥ì„ ë³´ê³  ë¬¸ë§¥ì„ ì´í•´í•˜ë©°, ì‚¬ìš©ìê°€ ë¬´ìŠ¨ ë‚´ìš©ì„ ì‘ì„±í•˜ê³  ìƒí’ˆì„ ì°¾ëŠ”ì§€ ì§‘ì¤‘ì ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤.
            ìŠ¤íƒ€ì¼: ë”°ëœ»í•˜ê³  ê³µê°í•˜ë©°, ë§ˆì¹˜ ì‹¤ì œ ì‡¼í•‘ ë„ìš°ë¯¸ì²˜ëŸ¼ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤.
            ëŒ€í™” ì „ëµ:
            ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ìƒí’ˆì„ êµ¬ì²´í™”í•˜ê¸° ìœ„í•´ ì ì ˆí•œ í›„ì† ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.
            ëŒ€í™”ì˜ íë¦„ì´ ëŠê¸°ì§€ ì•Šë„ë¡ ë¶€ë“œëŸ½ê²Œ ì´ì–´ê°‘ë‹ˆë‹¤.
            ëª©í‘œëŠ” ë‹¨ìˆœí•œ ì •ë³´ ì œê³µì´ ì•„ë‹Œ, ê³ ê°ì´ í•„ìš”í•œ ìƒí’ˆì„ ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì´ë¥¼ í†µí•´ ê³ ê°ì´ í¸ì•ˆí•˜ê³  ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‡¼í•‘ ê²½í—˜ì„ ëˆ„ë¦´ ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í•´ì•¼ í•©ë‹ˆë‹¤."""),
            MessagesPlaceholder(variable_name="message_history"),
            ("system", f"ë‹¤ìŒì€ ëŒ€í™”ì´ë ¥ì…ë‹ˆë‹¤ : \n{message_history}"),
            ("system", f"ë‹¤ìŒì€ ìƒí’ˆê²°ê³¼ì…ë‹ˆë‹¤ : \n{results_text}"),
            ("human", query)
        ])
        
        runnable = prompt | llm

        with_message_history = RunnableWithMessageHistory(
            runnable,
            get_session_history,
            input_messages_key="input",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤
            history_messages_key="message_history",
        )

        

        # âœ… LLM ì‹¤í–‰ ë° ë©”ì‹œì§€ ê¸°ë¡ ì—…ë°ì´íŠ¸
        response = with_message_history.invoke(
            {"input": query},
            config={"configurable": {"session_id": session_id}}
        )

        # âœ… Redisì— AI ì‘ë‹µ ì¶”ê°€
        session_history.add_message(AIMessage(content=response.content))

        # âœ… ë©”ì‹œì§€ ê¸°ë¡ì„ Redisì—ì„œ ê°€ì ¸ì˜¤ê¸°
        session_history = get_message_history(session_id)
        message_history = [
            {"type": type(msg).__name__, "content": msg.content if hasattr(msg, "content") else str(msg)}
            for msg in session_history.messages
        ]


        # âœ… ì¶œë ¥ ë””ë²„ê¹…
        print("*** Response:", response)
        print("*** Message History:", message_history)

        # âœ… JSON ë°˜í™˜
        return {
            "query": query,
            "results": results,
            "response": response.content,
            "message_history": message_history
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# âœ… FastAPI ì„œë²„ ì‹¤í–‰ (í¬íŠ¸ ê³ ì •: 5050)
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5050)