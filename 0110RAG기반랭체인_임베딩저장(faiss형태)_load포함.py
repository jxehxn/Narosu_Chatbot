from dotenv import load_dotenv
import os
import pandas as pd
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import faiss
import numpy as np
from datetime import datetime

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')

# âœ… ì˜¤ëŠ˜ ë‚ ì§œë¡œ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ ìƒì„±
faiss_file_path = f"faiss_index_{datetime.now().strftime('%Y%m%d')}.faiss"

# âœ… ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜
def load_excel_to_texts(file_path):
    try:
        data = pd.read_excel(file_path)
        texts = [
            " | ".join([f"{col}: {row[col]}" for col in data.columns])
            for _, row in data.iterrows()
        ]
        return texts
    except Exception as e:
        print(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise

# âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ (GPU â†’ CPU ë³€í™˜ í›„ ì €ì¥)
def save_faiss_index(index, file_path):
    cpu_index = faiss.index_gpu_to_cpu(index)  # GPU ì¸ë±ìŠ¤ë¥¼ CPUë¡œ ë³€í™˜
    faiss.write_index(cpu_index, file_path)
    print(f"âœ… FAISS ì¸ë±ìŠ¤ê°€ {file_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ
def load_faiss_index(file_path):
    try:
        index = faiss.read_index(file_path)
        print(f"âœ… FAISS ì¸ë±ìŠ¤ê°€ {file_path}ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return index
    except Exception as e:
        print(f"âŒ FAISS ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# âœ… OpenAI ì„ë² ë”© ë° FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
def create_and_save_faiss_index(file_path):
    texts = load_excel_to_texts(file_path)
    ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
    
    # âœ… ì„ë² ë”© ë²¡í„° ìƒì„±
    embeddings = ì„ë² ë”©.embed_documents(texts)
    
    # âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ë²¡í„° ì¶”ê°€ (GPU ì‚¬ìš©)
    index = faiss.IndexFlatL2(1536)
    index = faiss.index_cpu_to_all_gpus(index)
    index.add(np.array(embeddings, dtype=np.float32))
    
    # âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
    save_faiss_index(index, faiss_file_path)

# âœ… ë©”ì¸ ì‹¤í–‰ ë¡œì§: ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸ í›„ ë¡œë”© ë˜ëŠ” ìƒˆë¡œ ìƒì„±
if os.path.exists(faiss_file_path):
    print(f"ğŸ“¦ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ë°œê²¬: {faiss_file_path}")
    index = load_faiss_index(faiss_file_path)
else:
    print("âš™ï¸ FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    create_and_save_faiss_index("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")

# âœ… ë²¡í„° ìˆ˜ ë° ì°¨ì› ìˆ˜ ì¶œë ¥
if index:  
    print(f"âœ… ì €ì¥ëœ ë²¡í„° ìˆ˜: {index.ntotal}")
    print(f"âœ… ë²¡í„° ì°¨ì› ìˆ˜: {index.d}")
else:
    print("âŒ FAISS ì¸ë±ìŠ¤ ë¡œë”©ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")

#########============ì„ë² ë”© ì €ì¥ í›„ ë¡œë“œ============#########

# âœ… ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰ ë° LLM ì‘ë‹µ ìƒì„± (CMD ì…ë ¥ ì§€ì›)
def search_and_generate_response(file_path):
    query = input("ğŸ’¬ ìƒí’ˆ ê²€ìƒ‰ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    index = load_faiss_index(file_path)
    data = pd.read_excel("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœìƒí’ˆë¦¬ìŠ¤íŠ¸_OWNERCLAN_250102 í•„ìš”í•œ ë‚´ìš©ë§Œ.xlsx")

    if index is None:
        print("âŒ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    ì„ë² ë”© = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=API_KEY)
    query_embedding = ì„ë² ë”©.embed_documents([query])

    # âœ… FAISS ê²€ìƒ‰ ìˆ˜í–‰
    D, I = index.search(np.array(query_embedding, dtype=np.float32), k=5)
    print(f"ğŸ” ê²€ìƒ‰ëœ ì¸ë±ìŠ¤: {I}")

    # âœ… ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìƒí’ˆì½”ë“œ, ì›ë³¸ìƒí’ˆëª…, ì˜¤ë„ˆí´ëœíŒë§¤ê°€, ë°°ì†¡ë¹„, ì´ë¯¸ì§€ì¤‘, ì›ì‚°ì§€ë¡œ ì¶œë ¥
    results = []
    for idx in I[0]:
        result_row = data.iloc[idx]
        result_info = {
            "ìƒí’ˆì½”ë“œ": result_row["ìƒí’ˆì½”ë“œ"],
            "ì›ë³¸ìƒí’ˆëª…": result_row["ì›ë³¸ìƒí’ˆëª…"],
            "ì˜¤ë„ˆí´ëœíŒë§¤ê°€": result_row["ì˜¤ë„ˆí´ëœíŒë§¤ê°€"],
            "ë°°ì†¡ë¹„": result_row["ë°°ì†¡ë¹„"],
            "ì´ë¯¸ì§€ì¤‘": result_row["ì´ë¯¸ì§€ì¤‘"],
            "ì›ì‚°ì§€": result_row["ì›ì‚°ì§€"]
        }
        results.append(result_info)

    # âœ… LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì„¤ëª…
    llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18", api_key=API_KEY)
    response = llm.invoke(f"ì‚¬ìš©ìê°€ ìš”ì²­í•œ '{query}'ì— ëŒ€í•œ ìƒìœ„ ìƒí’ˆì€: {I}")
    print(f"âœ… LLM ì‘ë‹µ: {response}")
    print(f"âœ… ê²€ìƒ‰ëœ ìƒí’ˆ ì •ë³´: {results}")

# âœ… ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± (CMD ì…ë ¥ ì§€ì›)
search_and_generate_response(faiss_file_path)
